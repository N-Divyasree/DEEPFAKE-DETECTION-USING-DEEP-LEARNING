from google.colab import drive
drive.mount('/content/drive', force_remount=True)

DATASET_ROOT = '/content/drive/MyDrive/FF++'   # contains train/ and test/
MODEL_DIR = '/content/drive/MyDrive/deepfake_models'
LOG_DIR = '/content/drive/MyDrive/deepfake_logs'

import os
os.makedirs(MODEL_DIR, exist_ok=True)
os.makedirs(LOG_DIR, exist_ok=True)

# Check dataset
required_folders = [
    'train/real',
    'train/fake',
    'test/real',
    'test/fake'
]

for folder in required_folders:
    path = os.path.join(DATASET_ROOT, folder)
    if not os.path.isdir(path):
        raise FileNotFoundError(f"Missing folder: {path}")

print("Dataset OK! Structure is correct.")

import torch
from torch.utils.data import DataLoader, random_split
from torchvision.datasets import ImageFolder
from torchvision import transforms
import os

DATASET_ROOT = '/content/drive/MyDrive/FF++'

train_tf = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.3, contrast=0.3),
    transforms.ToTensor(),
])

test_tf = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# Load TRAIN dataset (real + fake inside folder)
full_train_ds = ImageFolder(os.path.join(DATASET_ROOT, 'train'), transform=train_tf)

# Create validation split = 20%
val_size = int(0.2 * len(full_train_ds))
train_size = len(full_train_ds) - val_size

train_ds, val_ds = random_split(full_train_ds, [train_size, val_size])

# Test dataset
test_ds = ImageFolder(os.path.join(DATASET_ROOT, 'test'), transform=test_tf)

# DataLoaders
train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False)
test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False)

print("Train count:", len(train_ds))
print("Val count:", len(val_ds))
print("Test count:", len(test_ds))

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.models import resnet18, ResNet18_Weights
from tqdm import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# ------------------------------
# 1. Load ResNet18 Model
# ------------------------------
model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)
model.fc = nn.Linear(model.fc.in_features, 2)   # 2 classes: real, fake
model = model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)
def train_one_epoch(model, loader, optimizer, criterion, epoch):
    model.train()
    total_loss = 0
    correct = 0

    loop = tqdm(loader, desc=f"Epoch {epoch} [Train]")

    for images, labels in loop:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()

        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # Metrics
        total_loss += loss.item()
        preds = outputs.argmax(dim=1)
        correct += (preds == labels).sum().item()

        loop.set_postfix(loss=loss.item())

    acc = 100 * correct / len(loader.dataset)
    return total_loss / len(loader), acc
def evaluate(model, loader, criterion):
    model.eval()
    total_loss = 0
    correct = 0

    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            total_loss += loss.item()
            preds = outputs.argmax(dim=1)
            correct += (preds == labels).sum().item()

    acc = 100 * correct / len(loader.dataset)
    return total_loss / len(loader), acc
EPOCHS = 10

for epoch in range(1, EPOCHS + 1):

    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, epoch)
    val_loss, val_acc = evaluate(model, val_loader, criterion)

    print(f"\nEpoch {epoch} Results:")
    print(f"Train Loss: {train_loss:.4f}  |  Train Acc: {train_acc:.2f}%")
    print(f"Val   Loss: {val_loss:.4f}  |  Val   Acc: {val_acc:.2f}%")
# ------------------------------
# 6. Test the Model
# ------------------------------
test_loss, test_acc = evaluate(model, test_loader, criterion)

print("\n=== TEST RESULTS ===")
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Acc : {test_acc:.2f}%")

MODEL_SAVE_PATH = "/content/drive/MyDrive/deepfake_models/resnet18_deepfake.pth"

torch.save(model.state_dict(), MODEL_SAVE_PATH)

print("Model saved to:", MODEL_SAVE_PATH)

from PIL import Image

def predict_image(img_path):
    model.eval()

    img = Image.open(img_path).convert("RGB")
    tf = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])

    img = tf(img).unsqueeze(0).to(device)

    with torch.no_grad():
        output = model(img)
        pred = output.argmax(dim=1).item()

    classes = ["real", "fake"]
    return classes[pred]
result = predict_image("/content/Fake 18.png")
print("Prediction:", result)


# Example:
# print(predict_image("/content/drive/MyDrive/sample.jpg"))